{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 26 00:25:37 2019\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 要下载的网页\n",
    "    url = 'https://www.biqubao.com/quanben/'\n",
    "    # 网站根网址\n",
    "    root_url = 'https://www.biqubao.com'\n",
    "    # 保存本地路径\n",
    "    path = 'F:\\\\project_zcy\\\\test'\n",
    "    \n",
    "    # 解析网址\n",
    "    req = requests.get(url)\n",
    "    # 设置编码，浏览器查看网站编码：F12，控制开输入document.characterSet回车即可查看\n",
    "    req.encoding = 'gbk'\n",
    "\n",
    "    # 获取网页所有内容\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "    # 查找网页中div的id为main的标签\n",
    "    list_tag = soup.div(id=\"main\")\n",
    "    # 查看div内所有里标签\n",
    "    li = list_tag[0](['li'])\n",
    "    # 删除第一个没用的标签\n",
    "    del li[0]\n",
    "    # 循环遍历\n",
    "    for i in li:\n",
    "        # 获取到a标签间的内容---小说类型\n",
    "        txt_type = i.a.string\n",
    "        # 获取a标签的href地址值---小说网址\n",
    "        short_url = (i(['a'])[1].get('href'))\n",
    "        # 获取第三个span标签的值---作者\n",
    "        author = i(['span'])[3].string\n",
    "\n",
    "        # 获取网页设置网页编码\n",
    "        req = requests.get(root_url + short_url)\n",
    "        req.encoding = 'gbk'\n",
    "\n",
    "        # 解析网页\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        list_tag = soup.div(id=\"list\")\n",
    "\n",
    "        # 获取小说名\n",
    "        name = list_tag[0].dl.dt.string\n",
    "\n",
    "        print(\"类型：{}    短址：{}   作者：{}   小说名：{}\".format(txt_type, short_url, author, name))\n",
    "\n",
    "        # 创建同名文件夹\n",
    "        # paths = path + '\\\\' + name\n",
    "        if not os.path.exists(path):\n",
    "            # 获取当前目录并组合新目录\n",
    "            # os.path.join(path, name)\n",
    "            os.mkdir(path)\n",
    "\n",
    "        # 循环所有的dd标签\n",
    "        for dd_tag in list_tag[0].dl.find_all('dd'):\n",
    "            # 章节名\n",
    "            zjName = dd_tag.string\n",
    "            # 章节地址\n",
    "            zjUrl = root_url + dd_tag.a.get('href')\n",
    "\n",
    "            # 访问网址爬取章节内容\n",
    "            req2 = requests.get(zjUrl)\n",
    "            req2.encoding = 'gbk'\n",
    "\n",
    "            zj_soup = BeautifulSoup(req2.text, \"html.parser\")\n",
    "            content_tag = zj_soup.div.find(id=\"content\")\n",
    "\n",
    "            # 把空格内容替换成换行\n",
    "            text = str(content_tag.text.replace('\\xa0', '\\n'))\n",
    "            text.replace('\\ufffd', '\\n')\n",
    "\n",
    "            # 写入文件操作'a'追加\n",
    "            with open(path + \"\\\\\" + name + \".txt\", 'a') as f:\n",
    "                f.write('\\n' + '\\n' + zjName)\n",
    "                f.write(text)\n",
    "                print(\"{}------->写入完毕\".format(zjName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
