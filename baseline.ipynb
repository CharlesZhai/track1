{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of          order_detail_id  order_id  order_total_num  order_amount  \\\n",
      "0                1000000   1000000              1.0         239.9   \n",
      "1                1001530   1001327              2.0         288.0   \n",
      "2                1001531   1001327              2.0         288.0   \n",
      "3                1001532   1001328              3.0         180.0   \n",
      "4                1001533   1001329              1.0         159.9   \n",
      "...                  ...       ...              ...           ...   \n",
      "2306866          3685495   3238358              1.0         199.0   \n",
      "2306867          3685496   3238359              2.0         299.8   \n",
      "2306868          3685497   3238359              2.0         299.8   \n",
      "2306869          3685498   3238360              1.0         168.0   \n",
      "2306870          3685499   3238361              1.0         102.0   \n",
      "\n",
      "         order_total_payment  order_total_discount       order_pay_time  \\\n",
      "0                       96.9                   0.0  2012-11-01 00:10:56   \n",
      "1                       96.9                   0.0  2013-08-31 23:14:42   \n",
      "2                       96.9                   0.0  2013-08-31 23:14:42   \n",
      "3                       89.7                   0.0  2013-08-31 22:06:35   \n",
      "4                       65.9                   0.0  2013-08-31 21:33:36   \n",
      "...                      ...                   ...                  ...   \n",
      "2306866                 59.9                   0.0  2013-01-10 19:24:31   \n",
      "2306867                 89.9                   0.0  2013-01-27 15:00:27   \n",
      "2306868                 89.9                   0.0  2013-01-27 15:00:27   \n",
      "2306869                 76.9                   0.0  2012-11-11 00:10:37   \n",
      "2306870                 49.9                   0.0  2013-07-10 14:22:14   \n",
      "\n",
      "         order_status  order_count  is_customer_rate  ...  customer_gender  \\\n",
      "0                   6          1.0               0.0  ...              NaN   \n",
      "1                   6          2.0               0.0  ...              NaN   \n",
      "2                   6          2.0               0.0  ...              NaN   \n",
      "3                   6          1.0               0.0  ...              NaN   \n",
      "4                   6          1.0               0.0  ...              NaN   \n",
      "...               ...          ...               ...  ...              ...   \n",
      "2306866             6          1.0               0.0  ...              0.0   \n",
      "2306867             6          2.0               0.0  ...              0.0   \n",
      "2306868             6          2.0               0.0  ...              0.0   \n",
      "2306869             6          1.0               0.0  ...              0.0   \n",
      "2306870             6          1.0               0.0  ...              0.0   \n",
      "\n",
      "         member_status  is_member_actived  goods_id  goods_class_id  \\\n",
      "0                  NaN                NaN       998             998   \n",
      "1                  NaN                NaN      1953            1953   \n",
      "2                  NaN                NaN      1083            1083   \n",
      "3                  NaN                NaN      1013            1013   \n",
      "4                  NaN                NaN      1628            1628   \n",
      "...                ...                ...       ...             ...   \n",
      "2306866            1.0                1.0      1173            1173   \n",
      "2306867            1.0                1.0      2513            2513   \n",
      "2306868            1.0                1.0       998             998   \n",
      "2306869            1.0                1.0      1423            1423   \n",
      "2306870            1.0                1.0      1043            1043   \n",
      "\n",
      "        goods_price goods_status  goods_has_discount      goods_list_time  \\\n",
      "0         54.909289          1.0                 0.0  2014-10-25 11:08:07   \n",
      "1         45.961352          0.0                 1.0  2013-08-28 17:27:50   \n",
      "2         53.035439          1.0                 0.0  2014-10-29 18:21:05   \n",
      "3         46.046917          1.0                 1.0  2014-10-25 11:00:00   \n",
      "4         50.722161          1.0                 0.0  2014-10-23 15:35:33   \n",
      "...             ...          ...                 ...                  ...   \n",
      "2306866   53.012016          1.0                 0.0  2014-10-25 10:14:59   \n",
      "2306867   42.693822          2.0                 0.0  2014-01-10 15:56:40   \n",
      "2306868   54.889036          1.0                 0.0  2014-10-25 11:08:07   \n",
      "2306869   52.078004          1.0                 0.0  2014-10-30 09:31:53   \n",
      "2306870   46.114765          1.0                 1.0  2014-10-28 00:03:12   \n",
      "\n",
      "           goods_delist_time  \n",
      "0        2014-11-01 11:08:07  \n",
      "1        2013-09-01 00:38:17  \n",
      "2        2014-11-05 18:21:05  \n",
      "3        2014-11-01 11:00:00  \n",
      "4        2014-10-30 15:35:33  \n",
      "...                      ...  \n",
      "2306866  2014-11-01 10:14:59  \n",
      "2306867  2014-01-11 12:46:19  \n",
      "2306868  2014-11-01 11:08:07  \n",
      "2306869  2014-11-06 09:31:53  \n",
      "2306870  2014-11-04 00:03:12  \n",
      "\n",
      "[2306871 rows x 29 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['goods_id'] = pd.factorize(raw['goods_id'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_detail_id', 'order_id', 'order_total_num', 'order_amount',\n",
       "       'order_total_payment', 'order_total_discount', 'order_pay_time',\n",
       "       'order_status', 'order_count', 'is_customer_rate',\n",
       "       'order_detail_status', 'order_detail_goods_num', 'order_detail_amount',\n",
       "       'order_detail_payment', 'order_detail_discount', 'customer_province',\n",
       "       'customer_city', 'member_id', 'customer_id', 'customer_gender',\n",
       "       'member_status', 'is_member_actived', 'goods_id', 'goods_class_id',\n",
       "       'goods_price', 'goods_status', 'goods_has_discount', 'goods_list_time',\n",
       "       'goods_delist_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prerpocess(raw, train='train'):\n",
    "    st = time.time()\n",
    "    data = pd.DataFrame(raw.groupby('customer_id')['customer_gender'].last().fillna(0))\n",
    "    data[['goods_id_last', 'goods_status_last', 'goods_price_last', 'goods_has_discount_last', 'goods_list_time_last', 'goods_delist_time_last']] = raw.groupby('customer_id')['goods_id', 'goods_status', 'goods_price', 'goods_has_discount', 'goods_list_time', 'goods_delist_time'].last()\n",
    "    data[['order_total_num_last', 'order_amount_last',\n",
    "       'order_total_payment_last', 'order_total_discount_last', 'order_pay_time_last',\n",
    "       'order_status_last', 'order_count_last', 'is_customer_rate_last',\n",
    "       'order_detail_status_last', 'order_detail_goods_num_last', 'order_detail_amount_last',\n",
    "       'order_detail_payment_last', 'order_detail_discount_last']] = raw.groupby('customer_id')['order_total_num', 'order_amount',\n",
    "       'order_total_payment', 'order_total_discount', 'order_pay_time',\n",
    "       'order_status', 'order_count', 'is_customer_rate',\n",
    "       'order_detail_status', 'order_detail_goods_num', 'order_detail_amount',\n",
    "       'order_detail_payment', 'order_detail_discount'].last()\n",
    "    data[['good_price_std', 'good_price_mean', 'good_price_min', 'good_price_max']] = raw.groupby('customer_id')['goods_price'].agg({'good_price_std':'std', 'good_price_mean':'mean', 'good_price_min':'min', 'good_price_max':'max'})\n",
    "    data[['order_detail_payment_std', 'order_detail_payment_mean', 'order_detail_payment_min', 'order_detail_payment_max']] = raw.groupby('customer_id')['order_detail_payment'].agg({'order_detail_payment_std':'std', 'order_detail_payment_mean':'mean', 'order_detail_payment_min':'min', 'order_detail_payment_max':'max'})\n",
    "    data['count'] = raw.groupby('customer_id')['order_id'].nunique()\n",
    "    data['goods_count'] = raw.groupby('customer_id')['order_total_num'].sum()\n",
    "    data['customer_province'] = raw.groupby('customer_id')['customer_province'].last()\n",
    "    data['customer_city'] = raw.groupby('customer_id')['customer_city'].last()\n",
    "    data[['is_customer_rate_ratio','is_customer_rate_sum']] = raw.groupby('customer_id')['is_customer_rate'].agg({'is_customer_rate_ratio':np.mean,'is_customer_rate_sum':np.sum})\n",
    "    data['order_detail_count'] = raw.groupby('customer_id')['customer_id'].count()\n",
    "    data[['goods_has_discount_sum','goods_has_discount_ave']] = raw.groupby('customer_id')['goods_has_discount'].agg({'goods_has_discount_sum':np.sum,'goods_has_discount_ave':np.mean})\n",
    "    data[['order_total_payment_sum','order_total_ave_pay']] = raw.groupby('customer_id')['order_total_payment'].agg({'order_total_payment_sum':np.sum,'order_total_ave_pay':np.mean})\n",
    "    data[['order_total_num_sum', 'order_total_num_ave']] = raw.groupby('customer_id')['order_total_num'].agg({'order_total_num_sum':np.sum,'order_total_num_ave':np.mean})\n",
    "\n",
    "    \n",
    "    def time2multi(x):\n",
    "        t=datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "        return pd.Series([t.month,t.day,t.weekday(),t.hour,t.minute,t.second])\n",
    "    \n",
    "    data[['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s']]=data['order_pay_time_last'].apply(time2multi)\n",
    "    #data[['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s']] = raw.groupby('customer_id')['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s'].last()\n",
    "    t_str='2013-01-01 00:00:00'\n",
    "    t=datetime.datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S')\n",
    "    data['goods_list_time_diff'] = data['goods_list_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\n",
    "    data['goods_delist_time_diff'] = data['goods_delist_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\n",
    "    data['goods_diff'] = data['goods_delist_time_diff'] - data['goods_list_time_diff']\n",
    "    data['order_pay_time_last_diff'] = data['order_pay_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\n",
    "    ed = time.time()\n",
    "    \n",
    "    print(ed-st)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263.07461810112\n",
      "288.5027780532837\n"
     ]
    }
   ],
   "source": [
    "train_raw = raw[raw['order_pay_time'] < '2013-07-31 23:59:59']\n",
    "train_raw = prerpocess(train_raw)\n",
    "label_raw = set(raw[raw['order_pay_time'] > '2013-07-31 23:59:59']['customer_id'].dropna())\n",
    "train_raw['labels']=train_raw.index.map(lambda x:int(x in label_raw))\n",
    "test = prerpocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_raw.drop(['goods_list_time_last', 'goods_delist_time_last', 'order_pay_time_last'], axis=1)\n",
    "train_data = train_data.drop(['customer_province', 'customer_city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catel = ['order_pay_time_last_h', 'order_pay_time_last_week', 'order_pay_time_last_m', 'order_detail_status_last', 'order_status_last', 'goods_status_last', 'goods_id_last', 'customer_gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data.drop('labels', axis=1), np.array(train_data['labels']), test_size=0.2, random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['customer_gender', 'goods_id_last', 'goods_status_last', 'order_detail_status_last', 'order_pay_time_last_h', 'order_pay_time_last_m', 'order_pay_time_last_week', 'order_status_last']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\ttraining's binary_logloss: 0.0675361\tvalid_1's binary_logloss: 0.068161\n",
      "[100]\ttraining's binary_logloss: 0.0659858\tvalid_1's binary_logloss: 0.0681118\n",
      "[150]\ttraining's binary_logloss: 0.064673\tvalid_1's binary_logloss: 0.0681932\n",
      "[200]\ttraining's binary_logloss: 0.0633046\tvalid_1's binary_logloss: 0.0683102\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.0669495\tvalid_1's binary_logloss: 0.0680802\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\ttraining's binary_logloss: 0.0673667\tvalid_1's binary_logloss: 0.0693849\n",
      "[100]\ttraining's binary_logloss: 0.0658522\tvalid_1's binary_logloss: 0.0692658\n",
      "[150]\ttraining's binary_logloss: 0.0646497\tvalid_1's binary_logloss: 0.0693199\n",
      "[200]\ttraining's binary_logloss: 0.0634475\tvalid_1's binary_logloss: 0.069381\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.0658908\tvalid_1's binary_logloss: 0.069265\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\ttraining's binary_logloss: 0.0668069\tvalid_1's binary_logloss: 0.071344\n",
      "[100]\ttraining's binary_logloss: 0.0653578\tvalid_1's binary_logloss: 0.0713287\n",
      "[150]\ttraining's binary_logloss: 0.0641966\tvalid_1's binary_logloss: 0.0714439\n",
      "[200]\ttraining's binary_logloss: 0.0629612\tvalid_1's binary_logloss: 0.0715215\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.0660466\tvalid_1's binary_logloss: 0.0712864\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\ttraining's binary_logloss: 0.0671488\tvalid_1's binary_logloss: 0.0699418\n",
      "[100]\ttraining's binary_logloss: 0.0655817\tvalid_1's binary_logloss: 0.0699227\n",
      "[150]\ttraining's binary_logloss: 0.0644264\tvalid_1's binary_logloss: 0.0699719\n",
      "[200]\ttraining's binary_logloss: 0.0633646\tvalid_1's binary_logloss: 0.0700309\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.0663013\tvalid_1's binary_logloss: 0.0698864\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[50]\ttraining's binary_logloss: 0.0667264\tvalid_1's binary_logloss: 0.0714638\n",
      "[100]\ttraining's binary_logloss: 0.0651542\tvalid_1's binary_logloss: 0.071398\n",
      "[150]\ttraining's binary_logloss: 0.063889\tvalid_1's binary_logloss: 0.0714841\n",
      "[200]\ttraining's binary_logloss: 0.0626371\tvalid_1's binary_logloss: 0.0715747\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.0657495\tvalid_1's binary_logloss: 0.0713796\n"
     ]
    }
   ],
   "source": [
    "y_pre = 0\n",
    "for train_index , test_index in kf.split(train_data):\n",
    "    X_train, X_valid, y_train, y_valid = train_data.drop('labels', axis=1).iloc[train_index], train_data.drop('labels', axis=1).iloc[test_index], np.array(train_data['labels'])[train_index], np.array(train_data['labels'])[test_index]\n",
    "    import lightgbm as lgb\n",
    "    param = {\n",
    "    'num_leaves':121,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective':'binary',\n",
    "    'max_depth':7,\n",
    "    'learning_rate':0.05,\n",
    "    'metric':'binary_logloss'}\n",
    "    trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    lgbm = lgb.train(param,trn_data,valid_sets=[trn_data,val_data],num_boost_round = 10000 ,early_stopping_rounds=150,verbose_eval=50, categorical_feature=catel)\n",
    "    test = test[X_train.columns]\n",
    "    y_pre += lgbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         column  importance\n",
      "34          order_total_num_sum           0\n",
      "4       goods_has_discount_last           1\n",
      "28         is_customer_rate_sum           6\n",
      "43       goods_delist_time_diff           9\n",
      "5          order_total_num_last          14\n",
      "13  order_detail_goods_num_last          14\n",
      "2             goods_status_last          22\n",
      "44                   goods_diff          22\n",
      "9             order_status_last          22\n",
      "36        order_pay_time_last_m          23\n",
      "11        is_customer_rate_last          23\n",
      "30       goods_has_discount_sum          31\n",
      "10             order_count_last          31\n",
      "38     order_pay_time_last_week          31\n",
      "12     order_detail_status_last          37\n",
      "14     order_detail_amount_last          53\n",
      "35          order_total_num_ave          61\n",
      "26                  goods_count          62\n",
      "15    order_detail_payment_last          65\n",
      "31       goods_has_discount_ave          67\n",
      "27       is_customer_rate_ratio          83\n",
      "29           order_detail_count         102\n",
      "42         goods_list_time_diff         109\n",
      "23     order_detail_payment_min         117\n",
      "6             order_amount_last         128\n",
      "7      order_total_payment_last         148\n",
      "22    order_detail_payment_mean         168\n",
      "33          order_total_ave_pay         169\n",
      "16   order_detail_discount_last         172\n",
      "24     order_detail_payment_max         174\n",
      "18              good_price_mean         185\n",
      "0               customer_gender         211\n",
      "3              goods_price_last         214\n",
      "19               good_price_min         238\n",
      "8     order_total_discount_last         239\n",
      "20               good_price_max         250\n",
      "21     order_detail_payment_std         268\n",
      "25                        count         269\n",
      "32      order_total_payment_sum         274\n",
      "37        order_pay_time_last_d         286\n",
      "17               good_price_std         436\n",
      "39        order_pay_time_last_h         562\n",
      "45     order_pay_time_last_diff         574\n",
      "41        order_pay_time_last_s         581\n",
      "40      order_pay_time_last_min         614\n",
      "1                 goods_id_last        1183\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\n",
    "        'column': X_train.columns,\n",
    "        'importance': lgbm.feature_importance(),\n",
    "    }).sort_values(by='importance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = y_pre/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x < 0.1:\n",
    "        return 0.1\n",
    "    if x > 0.9:\n",
    "        return 0.9\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['result'] = y_pre\n",
    "test['result'] = test['result'].map(f)\n",
    "subm = pd.DataFrame(test['result'])\n",
    "subm.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of          customer_id    result\n",
      "0            1000000  0.100000\n",
      "1            1000014  0.100000\n",
      "2            1000034  0.100000\n",
      "3            1000046  0.100000\n",
      "4            1000048  0.100000\n",
      "...              ...       ...\n",
      "1585981      2826570  0.100000\n",
      "1585982      2826571  0.100000\n",
      "1585983      2826572  0.100000\n",
      "1585984      2826573  0.100000\n",
      "1585985      2826574  0.189466\n",
      "\n",
      "[1585986 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "last_test = pd.read_csv('submission.csv')\n",
    "print(last_test.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                result\n",
      "customer_id          \n",
      "1000000      0.100000\n",
      "1000014      0.100000\n",
      "1000034      0.100000\n",
      "1000046      0.100000\n",
      "1000048      0.100000\n",
      "...               ...\n",
      "2826570      0.100000\n",
      "2826571      0.100000\n",
      "2826572      0.100000\n",
      "2826573      0.100000\n",
      "2826574      0.189466\n",
      "\n",
      "[1585986 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(subm.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result    0.102584\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['result'] = np.multiply(np.ones(1585986 ), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              result\n",
      "customer_id        \n",
      "1000000         0.5\n",
      "1000014         0.5\n",
      "1000034         0.5\n",
      "1000046         0.5\n",
      "1000048         0.5\n",
      "...             ...\n",
      "2826570         0.5\n",
      "2826571         0.5\n",
      "2826572         0.5\n",
      "2826573         0.5\n",
      "2826574         0.5\n",
      "\n",
      "[1585986 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "subm = pd.DataFrame(test['result'])\n",
    "print(subm.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('submissionstatic1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              result\n",
      "customer_id        \n",
      "1000000         0.8\n",
      "1000014         0.8\n",
      "1000034         0.8\n",
      "1000046         0.8\n",
      "1000048         0.8\n",
      "...             ...\n",
      "2826570         0.8\n",
      "2826571         0.8\n",
      "2826572         0.8\n",
      "2826573         0.8\n",
      "2826574         0.8\n",
      "\n",
      "[1585986 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "test['result'] = np.multiply(np.ones(1585986 ), 0.8)\n",
    "subm = pd.DataFrame(test['result'])\n",
    "print(subm.head)\n",
    "subm.to_csv('submissionstatic2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
